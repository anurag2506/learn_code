{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff121ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a726b06a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7fffc56",
   "metadata": {},
   "source": [
    "### Important Bug fixes:\n",
    "1. Mkae sure model and the tensors fed are in the same device: move inputs, targets, and models to the same device\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acacead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "def training():\n",
    "    # Setting seed for reproducability:\n",
    "    torch.manual_seed(23)\n",
    "    inp = torch.rand(size = (20,5),device=device)\n",
    "    tar = torch.rand(size = (20,1),device=device)\n",
    "    epochs = 10\n",
    "    model = nn.Linear(5,1).to(device=device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.9)\n",
    "    loss = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inp) # Forward pass\n",
    "        avg_loss = loss(output,tar) # Loss\n",
    "        avg_loss.backward() # Backward\n",
    "        optimizer.step() # Step: updates weights\n",
    "        \n",
    "        print(f\"{epoch+1}/{epochs} : {avg_loss.item()}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "487d4ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loss fo epoch-1/10 : 0.8533935546875\n",
      "2. Loss fo epoch-2/10 : 0.3009968400001526\n",
      "3. Loss fo epoch-3/10 : 0.08727125078439713\n",
      "4. Loss fo epoch-4/10 : 0.41451579332351685\n",
      "5. Loss fo epoch-5/10 : 0.6144632697105408\n",
      "6. Loss fo epoch-6/10 : 0.3466690480709076\n",
      "7. Loss fo epoch-7/10 : 0.06256309151649475\n",
      "8. Loss fo epoch-8/10 : 0.15740029513835907\n",
      "9. Loss fo epoch-9/10 : 0.37010303139686584\n",
      "10. Loss fo epoch-10/10 : 0.31146764755249023\n"
     ]
    }
   ],
   "source": [
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "927da7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Use a dataloader with mini-batch of size=5\\n2. model updates weights 4 times per epoch\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Improvements to be made:\n",
    "'''\n",
    "1. Use a dataloader with mini-batch of size=5\n",
    "2. model updates weights 4 times per epoch\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e339d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "def batched_training():\n",
    "    torch.manual_seed(23)\n",
    "    inp = torch.rand((20,5)).to(device)\n",
    "    tar = torch.rand((20,1)).to(device)\n",
    "    model = nn.Linear(5,1).to(device)\n",
    "    \n",
    "    \n",
    "    optim = SGD(model.parameters(), lr=1e-2, momentum=0.6)\n",
    "    loss = nn.MSELoss()\n",
    "    epochs = 10\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a11f0072",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbatched_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[53], line 18\u001b[0m, in \u001b[0;36mbatched_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inp,out \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatched_inp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatched_tar\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     19\u001b[0m         optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     20\u001b[0m         out \u001b[38;5;241m=\u001b[39m model(inp)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_proj/lib/python3.12/site-packages/torch/utils/data/dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_proj/lib/python3.12/site-packages/torch/utils/data/dataloader.py:384\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_iterator\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_BaseDataLoaderIter\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 384\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_SingleProcessDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_proj/lib/python3.12/site-packages/torch/utils/data/dataloader.py:660\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, loader):\n\u001b[0;32m--> 660\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_proj/lib/python3.12/site-packages/torch/utils/data/dataloader.py:601\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mtimeout\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collate_fn \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mcollate_fn\n\u001b[0;32m--> 601\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_sampler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_seed \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty((), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\u001b[38;5;241m.\u001b[39mrandom_(generator\u001b[38;5;241m=\u001b[39mloader\u001b[38;5;241m.\u001b[39mgenerator)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent_workers \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mpersistent_workers\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "batched_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1c7962c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n",
      "torch.Size([5, 5])\n",
      "torch.Size([5, 5])\n",
      "torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.rand((20,5)).to(device)\n",
    "out = torch.rand((20,1)).to(device)\n",
    "model = nn.Linear(5,1).to(device)\n",
    "\n",
    "batched_data = DataLoader(inp,batch_size=5,shuffle=True) # This still shows the underling dataset thats being batched(entire one)\n",
    "for batch in batched_data:\n",
    "    print(batch.shape) # This gives the dimensions of each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae26345e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
